{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyPrKLPfKHKrfDtiD0z85Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelmccormickudg/Gravitational_housing_model/blob/main/notebook_red_neural_ya_probada.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l12RoMV-ps5L",
        "outputId": "42d921da-4d84-4fb0-ba85-988b1905213a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (2.1.2)\n",
            "Requirement already satisfied: simplekml in /usr/local/lib/python3.12/dist-packages (1.3.6)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.0.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas) (25.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (3.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from pyogrio>=0.7.2->geopandas) (2025.11.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.17.0)\n",
            "props: (998, 41)\n",
            "grav : (320, 8)\n",
            "infl : (190, 8)\n",
            "denue: (2960, 43)\n",
            "props tras merges: (2680, 47)\n",
            "Index(['id', 'clee', 'nom_estab', 'raz_social', 'codigo_act', 'nombre_act',\n",
            "       'per_ocu', 'tipo_vial', 'nom_vial', 'tipo_v_e_1', 'nom_v_e_1',\n",
            "       'tipo_v_e_2', 'nom_v_e_2', 'tipo_v_e_3', 'nom_v_e_3', 'numero_ext',\n",
            "       'letra_ext', 'edificio', 'edificio_e', 'numero_int', 'letra_int',\n",
            "       'tipo_asent', 'nomb_asent', 'tipoCenCom', 'nom_CenCom', 'num_local',\n",
            "       'cod_postal', 'cve_ent', 'entidad', 'cve_mun', 'municipio', 'cve_loc',\n",
            "       'localidad', 'ageb', 'manzana', 'telefono', 'correoelec', 'www',\n",
            "       'tipoUniEco', 'latitud', 'longitud', 'fecha_alta', 'anio_alta'],\n",
            "      dtype='object')\n",
            "DENUE columnas normalizadas:          lat         lon                                          actividad\n",
            "0  20.300415 -103.194913  Comercio al por menor de paletas de hielo y he...\n",
            "1  20.288974 -103.193082                Comercio al por menor en minisupers\n",
            "2  20.296308 -103.243470                                     Banca m煤ltiple\n",
            "3  20.299159 -103.262481  Restaurantes con servicio de preparaci贸n de al...\n",
            "4  20.297165 -103.185369                Comercio al por menor en minisupers\n",
            "gdf_props: (2680, 48)\n",
            "gdf_denue: (2960, 44)\n",
            "Variables DENUE a帽adidas a props.\n",
            "Total de pares generados: 2670590\n",
            "Epoch 1/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2ms/step - Attr_accuracy: 0.5039 - Attr_loss: 5776.9067 - Fij_loss: 743040543482707968.0000 - Fij_mae: 464191328.0000 - loss: 743040543482707968.0000 - val_Attr_accuracy: 0.2579 - val_Attr_loss: 10929.6553 - val_Fij_loss: 3926291061407744.0000 - val_Fij_mae: 46397128.0000 - val_loss: 3926428500361216.0000\n",
            "Epoch 2/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2ms/step - Attr_accuracy: 0.4572 - Attr_loss: 6609.0142 - Fij_loss: 23917644226756608.0000 - Fij_mae: 97741280.0000 - loss: 23917644226756608.0000 - val_Attr_accuracy: 0.2560 - val_Attr_loss: 8712.0010 - val_Fij_loss: 2312144372629504.0000 - val_Fij_mae: 37119152.0000 - val_loss: 2312191617269760.0000\n",
            "Epoch 3/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2ms/step - Attr_accuracy: 0.4584 - Attr_loss: 5947.9282 - Fij_loss: 22660359122845696.0000 - Fij_mae: 92330480.0000 - loss: 22660359122845696.0000 - val_Attr_accuracy: 0.2582 - val_Attr_loss: 5972.7769 - val_Fij_loss: 2088781377175552.0000 - val_Fij_mae: 35405616.0000 - val_loss: 2088823387324416.0000\n",
            "Epoch 4/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2ms/step - Attr_accuracy: 0.4680 - Attr_loss: 5374.3975 - Fij_loss: 22347290366705664.0000 - Fij_mae: 90924032.0000 - loss: 22347290366705664.0000 - val_Attr_accuracy: 0.7469 - val_Attr_loss: 11796.5205 - val_Fij_loss: 1923591566262272.0000 - val_Fij_mae: 33974080.0000 - val_loss: 1923628476137472.0000\n",
            "Epoch 5/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 2ms/step - Attr_accuracy: 0.4750 - Attr_loss: 5043.2114 - Fij_loss: 22166659074621440.0000 - Fij_mae: 90086608.0000 - loss: 22166659074621440.0000 - val_Attr_accuracy: 0.2599 - val_Attr_loss: 6779.5205 - val_Fij_loss: 1664885687582720.0000 - val_Fij_mae: 31272770.0000 - val_loss: 1664925952901120.0000\n",
            "Epoch 6/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 2ms/step - Attr_accuracy: 0.4848 - Attr_loss: 4675.6396 - Fij_loss: 22119985665015808.0000 - Fij_mae: 89436280.0000 - loss: 22119985665015808.0000 - val_Attr_accuracy: 0.2655 - val_Attr_loss: 5691.4922 - val_Fij_loss: 1858843457880064.0000 - val_Fij_mae: 33578948.0000 - val_loss: 1858874864828416.0000\n",
            "Epoch 7/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2ms/step - Attr_accuracy: 0.4936 - Attr_loss: 4484.5874 - Fij_loss: 22001689380782080.0000 - Fij_mae: 88995240.0000 - loss: 22001689380782080.0000 - val_Attr_accuracy: 0.7469 - val_Attr_loss: 1937.2662 - val_Fij_loss: 1551798661808128.0000 - val_Fij_mae: 30382866.0000 - val_loss: 1551833289981952.0000\n",
            "Epoch 8/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2ms/step - Attr_accuracy: 0.5028 - Attr_loss: 4278.8140 - Fij_loss: 21843915904647168.0000 - Fij_mae: 88474256.0000 - loss: 21843915904647168.0000 - val_Attr_accuracy: 0.7469 - val_Attr_loss: 7056.5977 - val_Fij_loss: 1500424813150208.0000 - val_Fij_mae: 29870438.0000 - val_loss: 1500459307106304.0000\n",
            "Epoch 9/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 2ms/step - Attr_accuracy: 0.5103 - Attr_loss: 4151.9722 - Fij_loss: 21803633406377984.0000 - Fij_mae: 88232440.0000 - loss: 21803633406377984.0000 - val_Attr_accuracy: 0.3322 - val_Attr_loss: 3004.1763 - val_Fij_loss: 1392139158159360.0000 - val_Fij_mae: 28472790.0000 - val_loss: 1392174591639552.0000\n",
            "Epoch 10/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2ms/step - Attr_accuracy: 0.5183 - Attr_loss: 3954.4268 - Fij_loss: 21812457416687616.0000 - Fij_mae: 88051064.0000 - loss: 21812457416687616.0000 - val_Attr_accuracy: 0.2943 - val_Attr_loss: 5208.5068 - val_Fij_loss: 1449455094071296.0000 - val_Fij_mae: 29309750.0000 - val_loss: 1449491064422400.0000\n",
            "Epoch 11/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2ms/step - Attr_accuracy: 0.5230 - Attr_loss: 3979.4214 - Fij_loss: 21664044821774336.0000 - Fij_mae: 87741768.0000 - loss: 21664044821774336.0000 - val_Attr_accuracy: 0.7469 - val_Attr_loss: 5654.1470 - val_Fij_loss: 1543360930119680.0000 - val_Fij_mae: 30292456.0000 - val_loss: 1543396095164416.0000\n",
            "Epoch 12/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 2ms/step - Attr_accuracy: 0.5265 - Attr_loss: 4001.2244 - Fij_loss: 21649317378916352.0000 - Fij_mae: 87560616.0000 - loss: 21649317378916352.0000 - val_Attr_accuracy: 0.7469 - val_Attr_loss: 403.0335 - val_Fij_loss: 1420786590023680.0000 - val_Fij_mae: 28994822.0000 - val_loss: 1420820144455680.0000\n",
            "Epoch 13/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 2ms/step - Attr_accuracy: 0.5311 - Attr_loss: 4080.4543 - Fij_loss: 21726772819132416.0000 - Fij_mae: 87635176.0000 - loss: 21726772819132416.0000 - val_Attr_accuracy: 0.7469 - val_Attr_loss: 498.4044 - val_Fij_loss: 1503616779157504.0000 - val_Fij_mae: 29905628.0000 - val_loss: 1503649125629952.0000\n",
            "Epoch 14/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 2ms/step - Attr_accuracy: 0.5376 - Attr_loss: 3821.9541 - Fij_loss: 21730771433684992.0000 - Fij_mae: 87411336.0000 - loss: 21730771433684992.0000 - val_Attr_accuracy: 0.2713 - val_Attr_loss: 11525.2568 - val_Fij_loss: 1346705383489536.0000 - val_Fij_mae: 28125540.0000 - val_loss: 1346741353840640.0000\n",
            "Epoch 15/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2ms/step - Attr_accuracy: 0.5400 - Attr_loss: 3907.0842 - Fij_loss: 21744195353968640.0000 - Fij_mae: 87424968.0000 - loss: 21744195353968640.0000 - val_Attr_accuracy: 0.3838 - val_Attr_loss: 3091.2668 - val_Fij_loss: 1271967046959104.0000 - val_Fij_mae: 27175484.0000 - val_loss: 1271999796084736.0000\n",
            "Epoch 16/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2ms/step - Attr_accuracy: 0.5431 - Attr_loss: 3840.5757 - Fij_loss: 21666351219212288.0000 - Fij_mae: 87258736.0000 - loss: 21666351219212288.0000 - val_Attr_accuracy: 0.3930 - val_Attr_loss: 2989.1023 - val_Fij_loss: 1419857132257280.0000 - val_Fij_mae: 28961532.0000 - val_loss: 1419893639479296.0000\n",
            "Epoch 17/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2ms/step - Attr_accuracy: 0.5478 - Attr_loss: 3859.5300 - Fij_loss: 21664976829677568.0000 - Fij_mae: 87018568.0000 - loss: 21664976829677568.0000 - val_Attr_accuracy: 0.7469 - val_Attr_loss: 458.4503 - val_Fij_loss: 1441771397578752.0000 - val_Fij_mae: 29284336.0000 - val_loss: 1441808710107136.0000\n",
            "Epoch 18/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2ms/step - Attr_accuracy: 0.5466 - Attr_loss: 4078.4937 - Fij_loss: 21601129993338880.0000 - Fij_mae: 86949112.0000 - loss: 21601129993338880.0000 - val_Attr_accuracy: 0.4547 - val_Attr_loss: 1832.6208 - val_Fij_loss: 1203077516361728.0000 - val_Fij_mae: 26272776.0000 - val_loss: 1203114023583744.0000\n",
            "Epoch 19/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 2ms/step - Attr_accuracy: 0.5501 - Attr_loss: 4069.9802 - Fij_loss: 21561240484577280.0000 - Fij_mae: 86690808.0000 - loss: 21561240484577280.0000 - val_Attr_accuracy: 0.4226 - val_Attr_loss: 2762.7590 - val_Fij_loss: 1249428534984704.0000 - val_Fij_mae: 26892130.0000 - val_loss: 1249464639553536.0000\n",
            "Epoch 20/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2ms/step - Attr_accuracy: 0.5528 - Attr_loss: 4104.2651 - Fij_loss: 21646575042297856.0000 - Fij_mae: 86778408.0000 - loss: 21646575042297856.0000 - val_Attr_accuracy: 0.3174 - val_Attr_loss: 6794.0381 - val_Fij_loss: 1106145338982400.0000 - val_Fij_mae: 24754906.0000 - val_loss: 1106177819672576.0000\n",
            "Epoch 21/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2ms/step - Attr_accuracy: 0.5553 - Attr_loss: 4114.1978 - Fij_loss: 21593171418939392.0000 - Fij_mae: 86632200.0000 - loss: 21593171418939392.0000 - val_Attr_accuracy: 0.7469 - val_Attr_loss: 1922.0283 - val_Fij_loss: 1243408601448448.0000 - val_Fij_mae: 26948616.0000 - val_loss: 1243444034928640.0000\n",
            "Epoch 22/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 2ms/step - Attr_accuracy: 0.5566 - Attr_loss: 4184.1123 - Fij_loss: 21539215892283392.0000 - Fij_mae: 86449640.0000 - loss: 21539215892283392.0000 - val_Attr_accuracy: 0.7469 - val_Attr_loss: 461.9190 - val_Fij_loss: 1276926526226432.0000 - val_Fij_mae: 27519326.0000 - val_loss: 1276963436101632.0000\n",
            "Epoch 23/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 2ms/step - Attr_accuracy: 0.5577 - Attr_loss: 4221.3809 - Fij_loss: 21465868588285952.0000 - Fij_mae: 86333008.0000 - loss: 21465868588285952.0000 - val_Attr_accuracy: 0.9265 - val_Attr_loss: 46.1737 - val_Fij_loss: 1174337340047360.0000 - val_Fij_mae: 26088118.0000 - val_loss: 1174370760261632.0000\n",
            "Epoch 24/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2ms/step - Attr_accuracy: 0.5590 - Attr_loss: 4267.6426 - Fij_loss: 21522995948290048.0000 - Fij_mae: 86256976.0000 - loss: 21522995948290048.0000 - val_Attr_accuracy: 0.7469 - val_Attr_loss: 1068.9359 - val_Fij_loss: 1121972964556800.0000 - val_Fij_mae: 25323714.0000 - val_loss: 1122006787424256.0000\n",
            "Epoch 25/40\n",
            "\u001b[1m66765/66765\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 2ms/step - Attr_accuracy: 0.5620 - Attr_loss: 4215.4033 - Fij_loss: 21566714420396032.0000 - Fij_mae: 86239680.0000 - loss: 21566714420396032.0000 - val_Attr_accuracy: 0.7469 - val_Attr_loss: 10323.1523 - val_Fij_loss: 1143917428867072.0000 - val_Fij_mae: 25746496.0000 - val_loss: 1143950177992704.0000\n",
            "KML generado correctamente con 5000 l铆neas. Errores: 0\n",
            "Celdas en grilla: (21112, 1)\n",
            "gdf_grid con props + DENUE: (21112, 7)\n",
            "Distribuci贸n de clases recalculada:\n",
            "ITT_class\n",
            "1    20754\n",
            "2      358\n",
            "Name: count, dtype: int64\n",
            "Epoch 1/40\n",
            "\u001b[1m528/528\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Class_out_accuracy: 0.9270 - Class_out_loss: 0.7266 - ITT_out_loss: 1183097601231159296.0000 - ITT_out_mae: 6036003.0000 - loss: 1183101999277670400.0000 - val_Class_out_accuracy: 0.9919 - val_Class_out_loss: 0.0804 - val_ITT_out_loss: 13594594767798272.0000 - val_ITT_out_mae: 3318220.2500 - val_loss: 13597813845786624.0000\n",
            "Epoch 2/40\n",
            "\u001b[1m528/528\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Class_out_accuracy: 0.9924 - Class_out_loss: 0.0952 - ITT_out_loss: 3166062973634478080.0000 - ITT_out_mae: 15171777.0000 - loss: 3166067096803082240.0000 - val_Class_out_accuracy: 0.9953 - val_Class_out_loss: 0.0181 - val_ITT_out_loss: 13594594767798272.0000 - val_ITT_out_mae: 3318220.2500 - val_loss: 13597813845786624.0000\n",
            "Epoch 3/40\n",
            "\u001b[1m528/528\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Class_out_accuracy: 0.9960 - Class_out_loss: 0.0281 - ITT_out_loss: 2448105520196747264.0000 - ITT_out_mae: 12191856.0000 - loss: 2448109918243258368.0000 - val_Class_out_accuracy: 0.9979 - val_Class_out_loss: 0.0084 - val_ITT_out_loss: 13594594767798272.0000 - val_ITT_out_mae: 3318220.2500 - val_loss: 13597813845786624.0000\n",
            "Epoch 4/40\n",
            "\u001b[1m528/528\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Class_out_accuracy: 0.9958 - Class_out_loss: 0.0254 - ITT_out_loss: 43013968620421120.0000 - ITT_out_mae: 900127.6875 - loss: 43018289357520896.0000 - val_Class_out_accuracy: 0.9979 - val_Class_out_loss: 0.0071 - val_ITT_out_loss: 13594594767798272.0000 - val_ITT_out_mae: 3318220.2500 - val_loss: 13597813845786624.0000\n",
            "Epoch 5/40\n",
            "\u001b[1m528/528\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Class_out_accuracy: 0.9963 - Class_out_loss: 0.0229 - ITT_out_loss: 5250360986921074688.0000 - ITT_out_mae: 24961848.0000 - loss: 5250365384967585792.0000 - val_Class_out_accuracy: 0.9979 - val_Class_out_loss: 0.0051 - val_ITT_out_loss: 13594594767798272.0000 - val_ITT_out_mae: 3318220.2500 - val_loss: 13597813845786624.0000\n",
            "Epoch 6/40\n",
            "\u001b[1m528/528\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Class_out_accuracy: 0.9956 - Class_out_loss: 0.0305 - ITT_out_loss: 5706626976366723072.0000 - ITT_out_mae: 27117828.0000 - loss: 5706631374413234176.0000 - val_Class_out_accuracy: 0.9979 - val_Class_out_loss: 0.0036 - val_ITT_out_loss: 13594594767798272.0000 - val_ITT_out_mae: 3318220.2500 - val_loss: 13597813845786624.0000\n",
            "Resumen de clases predichas:\n",
            "Class_pred\n",
            "1    20907\n",
            "2      205\n",
            "Name: count, dtype: int64\n",
            "Valores 煤nicos en predicci贸n: {1: 20907, 2: 205}\n",
            "KML generado con 205 zonas. Errores: 0\n",
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7964 - loss: 1.0859\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9743 - loss: 1.0342\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9831 - loss: 0.9835\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.9858 - loss: 0.9227\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.9885 - loss: 0.8479\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9892 - loss: 0.7579\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9899 - loss: 0.6502\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9902 - loss: 0.5288\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.9903 - loss: 0.3940\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9905 - loss: 0.2682\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9899 - loss: 0.1703\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9904 - loss: 0.1024\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9908 - loss: 0.0642\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9907 - loss: 0.0467\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.9910 - loss: 0.0411\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9908 - loss: 0.0370\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9907 - loss: 0.0358\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9904 - loss: 0.0323\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9910 - loss: 0.0298\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9906 - loss: 0.0317\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x798121cd9fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Notebook completo\n",
        "# Predicci贸n de atracci贸n gravitacional entre propiedades y zonas de transformaci贸n territorial con redes neuronales + DENUE\n",
        "# 0. Instalaci贸n de librer铆as y setup\n",
        "\n",
        "!pip install geopandas shapely simplekml\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import tensorflow as tf\n",
        "from itertools import combinations\n",
        "from math import radians, sin, cos, asin, sqrt\n",
        "import simplekml\n",
        "import shapely.geometry\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Carga de archivos base\n",
        "\n",
        "# Rutas locales (como las tienes ahora):\n",
        "\n",
        "# Archivos principales del modelo\n",
        "PATH_PROPS   = \"/content/resultados_gravedad_propiedades_v2.xlsx\"\n",
        "PATH_GRAV    = \"/content/gravedad.csv\"\n",
        "PATH_INFL    = \"/content/influence_summary_cat3to5.csv\"\n",
        "PATH_DENUE   = \"/content/denue.xlsx\"\n",
        "\n",
        "# Cargar tablas\n",
        "props = pd.read_excel(PATH_PROPS)\n",
        "grav  = pd.read_csv(PATH_GRAV)\n",
        "infl  = pd.read_csv(PATH_INFL)\n",
        "denue = pd.read_excel(PATH_DENUE)\n",
        "\n",
        "print(\"props:\", props.shape)\n",
        "print(\"grav :\", grav.shape)\n",
        "print(\"infl :\", infl.shape)\n",
        "print(\"denue:\", denue.shape)\n",
        "\n",
        "\n",
        "# 2. Estandarizaci贸n de columnas y fusiones\n",
        "# 2.1. Propiedades, gravedad y radio de influencia\n",
        "\n",
        "# Normalizar nombres en props\n",
        "props = props.rename(columns={\n",
        "    \"coordinate/latitude\":  \"lat\",\n",
        "    \"coordinate/longitude\": \"lon\",\n",
        "    \"Masa\": \"mass\",\n",
        "    \"FuerzaTotal\": \"F_total\"\n",
        "})\n",
        "\n",
        "# Normalizar nombres en gravedad\n",
        "grav = grav.rename(columns={\n",
        "    \"coordinate/latitude\":  \"lat\",\n",
        "    \"coordinate/longitude\": \"lon\",\n",
        "    \"F_i\": \"F_node\"   # nombre est谩ndar para F_i de nodo\n",
        "})\n",
        "\n",
        "# Normalizar nombres en influencia\n",
        "infl = infl.rename(columns={\n",
        "    \"gravity_value\": \"F_inf\"\n",
        "})\n",
        "\n",
        "# Redondeo de coordenadas para merge aproximado\n",
        "def round_coords(df, ndigits=5):\n",
        "    df[\"lat_r\"] = df[\"lat\"].round(ndigits)\n",
        "    df[\"lon_r\"] = df[\"lon\"].round(ndigits)\n",
        "    return df\n",
        "\n",
        "props = round_coords(props)\n",
        "grav  = round_coords(grav)\n",
        "infl  = round_coords(infl)\n",
        "\n",
        "# Merge con gravedad\n",
        "props = props.merge(\n",
        "    grav[[\"lat_r\",\"lon_r\",\"S_i\",\"entropy_weight\",\"F_node\"]],\n",
        "    on=[\"lat_r\",\"lon_r\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Merge con resumen de influencia (radio R_influence_km)\n",
        "props = props.merge(\n",
        "    infl[[\"lat_r\",\"lon_r\",\"R_influence_km\"]],\n",
        "    on=[\"lat_r\",\"lon_r\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Rellenar NaN con valores razonables\n",
        "props[\"R_influence_km\"] = props[\"R_influence_km\"].fillna(props[\"R_influence_km\"].median())\n",
        "props[\"S_i\"]            = props[\"S_i\"].fillna(props[\"S_i\"].median())\n",
        "props[\"F_node\"]         = props[\"F_node\"].fillna(props[\"F_node\"].median())\n",
        "\n",
        "print(\"props tras merges:\", props.shape)\n",
        "\n",
        "\n",
        "# 2.2. Preparaci贸n de DENUE\n",
        "\n",
        "# Columnas reales de tu DENUE:\n",
        "\n",
        "print(denue.columns)\n",
        "\n",
        "\n",
        "# Tienen latitud, longitud, nombre_act. Las normalizamos:\n",
        "\n",
        "denue = denue.rename(columns={\n",
        "    \"latitud\": \"lat\",\n",
        "    \"longitud\": \"lon\",\n",
        "    \"nombre_act\": \"actividad\"\n",
        "})\n",
        "\n",
        "print(\"DENUE columnas normalizadas:\", denue[[\"lat\",\"lon\",\"actividad\"]].head())\n",
        "\n",
        "\n",
        "# 3. GeoDataFrames y proyecci贸n\n",
        "\n",
        "# Usaremos un CRS m茅trico local para Chapala. Ajusta el EPSG si necesitas otro, pero este patr贸n es v谩lido.\n",
        "\n",
        "# Propiedades\n",
        "gdf_props = gpd.GeoDataFrame(\n",
        "    props,\n",
        "    geometry=gpd.points_from_xy(props[\"lon\"], props[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(\"EPSG:6372\")   # CRS m茅trico local (ajustable)\n",
        "\n",
        "# DENUE\n",
        "gdf_denue = gpd.GeoDataFrame(\n",
        "    denue,\n",
        "    geometry=gpd.points_from_xy(denue[\"lon\"], denue[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(gdf_props.crs)\n",
        "\n",
        "print(\"gdf_props:\", gdf_props.shape)\n",
        "print(\"gdf_denue:\", gdf_denue.shape)\n",
        "\n",
        "\n",
        "# 4. Variables territoriales DENUE por propiedad\n",
        "\n",
        "# Calculamos para cada propiedad:\n",
        "\n",
        "# denue_total_500m: n煤mero de establecimientos a 500 m\n",
        "\n",
        "# denue_turismo_500m: establecimientos tur铆sticos (hotel, alojamiento, restaurantes, bares)\n",
        "\n",
        "# denue_diversidad_500m: n煤mero de tipos de actividad distintos\n",
        "\n",
        "buffer_radius = 500  # metros\n",
        "\n",
        "def es_turismo(act):\n",
        "    if isinstance(act, str):\n",
        "        act_low = act.lower()\n",
        "        if \"hotel\" in act_low or \"alojamiento\" in act_low or \"hospedaje\" in act_low:\n",
        "            return 1\n",
        "        if \"restaurante\" in act_low or \"restaurant\" in act_low or \"bar\" in act_low:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "gdf_denue[\"turistico\"] = gdf_denue[\"actividad\"].apply(es_turismo)\n",
        "\n",
        "denue_total = []\n",
        "denue_tur   = [] # Changed from denu_tur to denue_tur\n",
        "denue_div   = [] # Changed from denu_div to denue_div\n",
        "\n",
        "for geom in gdf_props.geometry:\n",
        "    buf = geom.buffer(buffer_radius)\n",
        "    df_loc = gdf_denue[gdf_denue.geometry.within(buf)]\n",
        "\n",
        "    denue_total.append(len(df_loc))\n",
        "    denue_tur.append(df_loc[\"turistico\"].sum())\n",
        "    denue_div.append(df_loc[\"actividad\"].nunique())\n",
        "\n",
        "props[\"denue_total_500m\"]      = denue_total\n",
        "props[\"denue_turismo_500m\"]    = denue_tur\n",
        "props[\"denue_diversidad_500m\"] = denue_div\n",
        "\n",
        "print(\"Variables DENUE a帽adidas a props.\")\n",
        "\n",
        "\n",
        "# 5. Funci贸n Haversine\n",
        "\n",
        "def haversine(lat1, lon1, lat2, lon2, R=6371):\n",
        "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2\n",
        "    c = 2*asin(sqrt(a))\n",
        "    return R*c  # km\n",
        "\n",
        "\n",
        "# 6. Dataset de pares (i, j) y etiqueta Fij\n",
        "\n",
        "# Definimos:\n",
        "\n",
        "# # \n",
        "# # \n",
        "# # \n",
        "# # \n",
        "# # \n",
        "# # \n",
        "# # \n",
        "# # \n",
        "# # =\n",
        "# # \n",
        "# # \n",
        "# # +\n",
        "# # \n",
        "# # \n",
        "# # 2\n",
        "# # \n",
        "# # 1\n",
        "# # 1\n",
        "# # +\n",
        "# # \n",
        "# # \n",
        "# # \n",
        "# # \n",
        "# # \n",
        "# # \n",
        "# # \n",
        "# # F\n",
        "# # ij\n",
        "# # label\n",
        "# #\n",
        "\n",
        "# # =\n",
        "# # 2\n",
        "# # F\n",
        "# #\n",
        "\n",
        "# # +F\n",
        "# # j\n",
        "# #\n",
        "\n",
        "# #\n",
        "\n",
        "# # \n",
        "# # 1+dist\n",
        "# # ij\n",
        "# # 尾\n",
        "# #\n",
        "\n",
        "# # 1\n",
        "# #\n",
        "\n",
        "\n",
        "# y una etiqueta binaria de atracci贸n seg煤n R_influence_km de la propiedad i.\n",
        "\n",
        "pairs = []\n",
        "beta = 2.0\n",
        "max_radius_km = 3.0  # distancia m谩xima para considerar pares\n",
        "\n",
        "indices = props.index.to_list()\n",
        "\n",
        "for i, j in combinations(indices, 2):\n",
        "    pi = props.loc[i]\n",
        "    pj = props.loc[j]\n",
        "\n",
        "    dist_ij = haversine(pi[\"lat\"], pi[\"lon\"], pj[\"lat\"], pj[\"lon\"])\n",
        "    if dist_ij > max_radius_km:\n",
        "        continue\n",
        "\n",
        "    Fi = pi[\"F_node\"] if not np.isnan(pi[\"F_node\"]) else pi[\"F_total\"]\n",
        "    Fj = pj[\"F_node\"] if not np.isnan(pj[\"F_node\"]) else pj[\"F_total\"]\n",
        "\n",
        "    Fij_label = ((Fi + Fj) / 2.0) * (1.0 / (1.0 + dist_ij**beta))\n",
        "\n",
        "    attract_ij = 1 if dist_ij <= pi[\"R_influence_km\"] else 0\n",
        "\n",
        "    row = {\n",
        "        \"i\": i,\n",
        "        \"j\": j,\n",
        "        \"dist_ij\": dist_ij,\n",
        "        \"mass_i\": pi[\"mass\"],\n",
        "        \"mass_j\": pj[\"mass\"],\n",
        "        \"F_i\": Fi,\n",
        "        \"F_j\": Fj,\n",
        "        \"S_i\": pi[\"S_i\"],\n",
        "        \"S_j\": pj[\"S_i\"],\n",
        "\n",
        "        # variables DENUE por propiedad\n",
        "        \"denue_total_i\":      pi[\"denue_total_500m\"],\n",
        "        \"denue_total_j\":      pj[\"denue_total_500m\"],\n",
        "        \"denue_turismo_i\":    pi[\"denue_turismo_500m\"],\n",
        "        \"denue_turismo_j\":    pj[\"denue_turismo_500m\"],\n",
        "        \"denue_div_i\":        pi[\"denue_diversidad_500m\"],\n",
        "        \"denue_div_j\":        pj[\"denue_diversidad_500m\"],\n",
        "\n",
        "        \"Fij_label\": Fij_label,\n",
        "        \"attract_label\": attract_ij\n",
        "    }\n",
        "    pairs.append(row)\n",
        "\n",
        "pairs_df = pd.DataFrame(pairs)\n",
        "pairs_df = pairs_df.fillna(pairs_df.median(numeric_only=True))\n",
        "\n",
        "print(\"Total de pares generados:\", len(pairs_df))\n",
        "\n",
        "\n",
        "# 7. MODELO 1: Red neuronal Fij + Atracci贸n entre propiedades\n",
        "# 7.1 Preparar features y escalado\n",
        "\n",
        "feature_cols = [\n",
        "    \"dist_ij\",\n",
        "    \"mass_i\",\"mass_j\",\n",
        "    \"F_i\",\"F_j\",\n",
        "    \"S_i\",\"S_j\",\n",
        "    \"denue_total_i\",\"denue_total_j\",\n",
        "    \"denue_turismo_i\",\"denue_turismo_j\",\n",
        "    \"denue_div_i\",\"denue_div_j\"\n",
        "]\n",
        "\n",
        "X = pairs_df[feature_cols].values\n",
        "y_reg = pairs_df[\"Fij_label\"].values\n",
        "y_cls = pairs_df[\"attract_label\"].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "Xtr, Xte, yr_tr, yr_te, yc_tr, yc_te = train_test_split(\n",
        "    X_scaled, y_reg, y_cls, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "Xtr.shape, Xte.shape\n",
        "\n",
        "\n",
        "# 7.2 Definir y entrenar modelo multitarea\n",
        "\n",
        "inputs = tf.keras.Input(shape=(Xtr.shape[1],))\n",
        "\n",
        "x = tf.keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
        "x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(16, activation=\"relu\")(x)\n",
        "\n",
        "out_reg = tf.keras.layers.Dense(1, name=\"Fij\")(x)\n",
        "out_cls = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"Attr\")(x)\n",
        "\n",
        "model1 = tf.keras.Model(inputs=inputs, outputs=[out_reg, out_cls])\n",
        "\n",
        "model1.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss={\"Fij\": \"mse\", \"Attr\": \"binary_crossentropy\"},\n",
        "    metrics={\"Fij\": \"mae\", \"Attr\": \"accuracy\"}\n",
        ")\n",
        "\n",
        "history1 = model1.fit(\n",
        "    Xtr,\n",
        "    {\"Fij\": yr_tr, \"Attr\": yc_tr},\n",
        "    validation_data=(Xte, {\"Fij\": yr_te, \"Attr\": yc_te}),\n",
        "    epochs=40,\n",
        "    batch_size=32,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        ")\n",
        "\n",
        "\n",
        "# 8. KML de pares de propiedades atra铆das\n",
        "\n",
        "from simplekml import Kml, Color\n",
        "\n",
        "# Verificamos existencia de columnas necesarias y ejecutamos predicci贸n si es necesario\n",
        "if \"attr_prob\" not in pairs_df.columns or \"Fij_pred\" not in pairs_df.columns:\n",
        "    pred_fij, pred_attr = model1.predict(X_scaled, verbose=0)\n",
        "    pairs_df[\"Fij_pred\"] = pred_fij.flatten()\n",
        "    pairs_df[\"attr_prob\"] = pred_attr.flatten()\n",
        "\n",
        "# Umbral de probabilidad\n",
        "thr_prob = 0.5\n",
        "high_pairs = pairs_df[pairs_df[\"attr_prob\"] >= thr_prob].copy()\n",
        "\n",
        "# Limitar m谩ximo a 5000 l铆neas por razones de rendimiento\n",
        "high_pairs = high_pairs.head(5000)\n",
        "\n",
        "if high_pairs.empty:\n",
        "    print(f\"No hay pares con probabilidad >= {thr_prob}\")\n",
        "else:\n",
        "    kml1 = Kml()\n",
        "    errores = 0\n",
        "    for _, row in high_pairs.iterrows():\n",
        "        try:\n",
        "            pi = props.loc[int(row[\"i\"])]\n",
        "            pj = props.loc[int(row[\"j\"])]\n",
        "\n",
        "            if any(pd.isna([pi[\"lat\"], pi[\"lon\"], pj[\"lat\"], pj[\"lon\"]])):\n",
        "                continue\n",
        "\n",
        "            ls = kml1.newlinestring(\n",
        "                name=f\"p={row['attr_prob']:.2f}\",\n",
        "                coords=[(pi[\"lon\"], pi[\"lat\"]), (pj[\"lon\"], pj[\"lat\"])]\n",
        "            )\n",
        "            ls.style.linestyle.width = 2\n",
        "            ls.style.linestyle.color = Color.blue\n",
        "        except Exception as e:\n",
        "            errores += 1\n",
        "            continue\n",
        "\n",
        "    kml1.save(\"atraccion_propiedades_fij_denue.kml\")\n",
        "    print(f\"KML generado correctamente con {len(high_pairs)-errores} l铆neas. Errores: {errores}\")\n",
        "\n",
        "\n",
        "# 9. MODELO 2: Zonas de transformaci贸n territorial (vectorial + DENUE)\n",
        "# 9.1 Construcci贸n de grilla espacial\n",
        "\n",
        "minx, miny, maxx, maxy = gdf_props.to_crs(gdf_props.crs).total_bounds\n",
        "cell_size = 150  # metros\n",
        "\n",
        "xs = np.arange(minx, maxx, cell_size)\n",
        "ys = np.arange(miny, maxy, cell_size)\n",
        "\n",
        "polygons = []\n",
        "for x in xs:\n",
        "    for y in ys:\n",
        "        polygons.append(shapely.geometry.box(x, y, x+cell_size, y+cell_size))\n",
        "\n",
        "gdf_grid = gpd.GeoDataFrame(geometry=polygons, crs=gdf_props.crs)\n",
        "\n",
        "print(\"Celdas en grilla:\", gdf_grid.shape)\n",
        "\n",
        "# Removed redundant feature preparation and check from here\n",
        "\n",
        "\n",
        "# 9.2 Agregar propiedades a la grilla\n",
        "\n",
        "join_props = gpd.sjoin(gdf_props, gdf_grid, how=\"left\", predicate=\"within\")\n",
        "\n",
        "agg_props = join_props.groupby(\"index_right\").agg({\n",
        "    \"mass\": \"sum\",\n",
        "    \"F_total\": \"sum\",\n",
        "    \"S_i\": \"mean\",\n",
        "    \"F_node\": \"mean\"\n",
        "}).rename(columns={\n",
        "    \"mass\": \"mass_sum\",\n",
        "    \"F_total\": \"F_sum\",\n",
        "    \"S_i\": \"S_mean\",\n",
        "    \"F_node\": \"Fnode_mean\"\n",
        "})\n",
        "\n",
        "gdf_grid = gdf_grid.join(agg_props, how=\"left\")\n",
        "gdf_grid[[\"mass_sum\",\"F_sum\",\"S_mean\",\"Fnode_mean\"]] = gdf_grid[[\"mass_sum\",\"F_sum\",\"S_mean\",\"Fnode_mean\"]].fillna(0)\n",
        "\n",
        "\n",
        "# 9.3 Agregar DENUE a la grilla\n",
        "\n",
        "join_denue = gpd.sjoin(gdf_denue, gdf_grid, how=\"left\", predicate=\"within\")\n",
        "\n",
        "agg_denue = join_denue.groupby(\"index_right\").agg({\n",
        "    \"actividad\": \"nunique\",\n",
        "    \"turistico\": \"sum\"\n",
        "}).rename(columns={\n",
        "    \"actividad\": \"denue_div_grid\",\n",
        "    \"turistico\": \"denue_turismo_grid\"\n",
        "})\n",
        "\n",
        "gdf_grid = gdf_grid.join(agg_denue, how=\"left\")\n",
        "gdf_grid[[\"denue_div_grid\",\"denue_turismo_grid\"]] = gdf_grid[[\"denue_div_grid\",\"denue_turismo_grid\"]].fillna(0)\n",
        "\n",
        "print(\"gdf_grid con props + DENUE:\", gdf_grid.shape)\n",
        "\n",
        "\n",
        "# 9.4 ITT y clases territoriales\n",
        "\n",
        "a1, a2, a3, a4 = 1.0, 0.5, 0.3, 0.4\n",
        "\n",
        "gdf_grid[\"ITT\"] = (\n",
        "    a1*gdf_grid[\"F_sum\"] +\n",
        "    a2*gdf_grid[\"mass_sum\"] -\n",
        "    a3*gdf_grid[\"S_mean\"] +\n",
        "    a4*gdf_grid[\"denue_turismo_grid\"]\n",
        ")\n",
        "\n",
        "gdf_grid = gdf_grid.copy()\n",
        "gdf_grid[\"ITT_rank\"] = gdf_grid[\"ITT\"].rank(pct=True)\n",
        "\n",
        "def classify_balanced(rank):\n",
        "    if rank <= 0.33:\n",
        "        return 0\n",
        "    elif rank <= 0.66:\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "gdf_grid[\"ITT_class\"] = gdf_grid[\"ITT_rank\"].apply(classify_balanced)\n",
        "print(\"Distribuci贸n de clases recalculada:\")\n",
        "print(gdf_grid[\"ITT_class\"].value_counts())\n",
        "\n",
        "\n",
        "gdf_grid[[\"ITT\",\"ITT_class\"]].head()\n",
        "\n",
        "\n",
        "# 9.5 MLP vectorial para ITT + clase\n",
        "\n",
        "features_grid = [\n",
        "    \"mass_sum\",\"F_sum\",\"S_mean\",\"Fnode_mean\",\n",
        "    \"denue_div_grid\",\"denue_turismo_grid\"\n",
        "]\n",
        "\n",
        "Xg = gdf_grid[features_grid].values\n",
        "yI = gdf_grid[\"ITT\"].values\n",
        "yC = gdf_grid[\"ITT_class\"].values\n",
        "\n",
        "scaler_g = StandardScaler()\n",
        "Xg_scaled = scaler_g.fit_transform(Xg)\n",
        "\n",
        "Xg_tr, Xg_te, yI_tr, yI_te, yC_tr, yC_te = train_test_split(\n",
        "    Xg_scaled, yI, yC, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "inp_g = tf.keras.Input(shape=(Xg_tr.shape[1],))\n",
        "z = tf.keras.layers.Dense(32, activation=\"relu\")(inp_g)\n",
        "z = tf.keras.layers.Dense(16, activation=\"relu\")(z)\n",
        "z = tf.keras.layers.Dropout(0.2)(z)\n",
        "\n",
        "ITT_out   = tf.keras.layers.Dense(1, name=\"ITT_out\")(z)\n",
        "Class_out = tf.keras.layers.Dense(3, activation=\"softmax\", name=\"Class_out\")(z)\n",
        "\n",
        "model2 = tf.keras.Model(inp_g, [ITT_out, Class_out])\n",
        "\n",
        "model2.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss={\"ITT_out\": \"mse\", \"Class_out\": \"sparse_categorical_crossentropy\"},\n",
        "    metrics={\"ITT_out\": \"mae\", \"Class_out\": \"accuracy\"}\n",
        ")\n",
        "\n",
        "history2 = model2.fit(\n",
        "    Xg_tr,\n",
        "    {\"ITT_out\": yI_tr, \"Class_out\": yC_tr},\n",
        "    validation_data=(Xg_te, {\"ITT_out\": yI_te, \"Class_out\": yC_te}),\n",
        "    epochs=40,\n",
        "    batch_size=32,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        ")\n",
        "\n",
        "\n",
        "# 9.6 Predicciones y KML de zonas de transformaci贸n\n",
        "\n",
        "import simplekml\n",
        "\n",
        "# Verificar y forzar predicci贸n si hace falta\n",
        "if \"ITT_pred\" not in gdf_grid.columns or \"Class_pred\" not in gdf_grid.columns:\n",
        "    Xg_all = scaler_g.transform(gdf_grid[features_grid].values)\n",
        "    ITT_pred_all, Class_pred_all = model2.predict(Xg_all, verbose=0)\n",
        "    gdf_grid[\"ITT_pred\"]   = ITT_pred_all.flatten()\n",
        "    gdf_grid[\"Class_pred\"] = Class_pred_all.argmax(axis=1)\n",
        "print(\"Resumen de clases predichas:\")\n",
        "print(gdf_grid[\"Class_pred\"].value_counts())\n",
        "\n",
        "\n",
        "# Diagn贸stico\n",
        "print(\"Valores 煤nicos en predicci贸n:\", gdf_grid[\"Class_pred\"].value_counts().to_dict())\n",
        "\n",
        "# Filtrar clase 2\n",
        "zonas_altas = gdf_grid[gdf_grid[\"Class_pred\"] == 2].copy()\n",
        "\n",
        "if zonas_altas.empty:\n",
        "    print(\"Advertencia: no se encontraron zonas de transformaci贸n territorial clase 2.\")\n",
        "else:\n",
        "    kml2 = simplekml.Kml()\n",
        "errores = 0\n",
        "\n",
        "for _, row in zonas_altas.iterrows():\n",
        "    try:\n",
        "        poly = row.geometry\n",
        "        if poly and hasattr(poly, \"exterior\"):\n",
        "            pol = kml2.newpolygon()\n",
        "            pol.outerboundaryis = list(poly.exterior.coords)\n",
        "            pol.style.polystyle.color = simplekml.Color.changealphaint(120, simplekml.Color.red)\n",
        "            pol.name = f\"Clase {row['Class_pred']}, ITT={row['ITT_pred']:.2f}\"\n",
        "    except Exception as e:\n",
        "        errores += 1\n",
        "        print(f\"Error al procesar pol铆gono: {e}\")\n",
        "\n",
        "kml2.save(\"zonas_transformacion_denue.kml\")\n",
        "print(f\"KML generado con {len(zonas_altas) - errores} zonas. Errores: {errores}\")\n",
        "\n",
        "\n",
        "\n",
        "# 10. CNN espacial (opcional) para validaci贸n cruzada\n",
        "\n",
        "# Si quieres la parte raster / CNN, puedes a帽adir esta secci贸n. Si por ahora quieres mantenerlo simple, puedes omitirla.\n",
        "\n",
        "# Asignar 铆ndices de fila/columna a cada celda de la grilla\n",
        "gdf_grid[\"centroid\"] = gdf_grid.geometry.centroid\n",
        "minx_c, miny_c, maxx_c, maxy_c = gdf_grid.total_bounds\n",
        "\n",
        "gdf_grid[\"row\"] = ((gdf_grid[\"centroid\"].y - miny_c) // cell_size).astype(int)\n",
        "gdf_grid[\"col\"] = ((gdf_grid[\"centroid\"].x - minx_c) // cell_size).astype(int)\n",
        "\n",
        "max_row = gdf_grid[\"row\"].max() + 1\n",
        "max_col = gdf_grid[\"col\"].max() + 1\n",
        "\n",
        "channels = features_grid  # mismas variables de entrada\n",
        "grid_tensor = np.zeros((max_row, max_col, len(channels)), dtype=float)\n",
        "label_tensor = np.zeros((max_row, max_col), dtype=int)\n",
        "\n",
        "for _, r in gdf_grid.iterrows():\n",
        "    i = r[\"row\"]\n",
        "    j = r[\"col\"]\n",
        "    for c_idx, c_name in enumerate(channels):\n",
        "        grid_tensor[i, j, c_idx] = r[c_name]\n",
        "    label_tensor[i, j] = r[\"ITT_class\"]\n",
        "\n",
        "# Normalizaci贸n por canal\n",
        "for c_idx in range(len(channels)):\n",
        "    ch = grid_tensor[:, :, c_idx]\n",
        "    mu = ch.mean()\n",
        "    sigma = ch.std() if ch.std() > 0 else 1.0\n",
        "    grid_tensor[:, :, c_idx] = (ch - mu) / sigma\n",
        "\n",
        "# A帽adir dimensi贸n batch\n",
        "X_cnn = np.expand_dims(grid_tensor, axis=0)\n",
        "y_cnn = np.expand_dims(label_tensor, axis=0)\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "input_shape = X_cnn.shape[1:]\n",
        "\n",
        "inputs_cnn = layers.Input(shape=input_shape)\n",
        "y = layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(inputs_cnn)\n",
        "# Removed MaxPooling2D layers to maintain spatial resolution\n",
        "y = layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(y)\n",
        "y = layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(y)\n",
        "y = layers.Dropout(0.3)(y) # Apply dropout to feature maps\n",
        "# Replaced Flatten and Dense layers with a Conv2D layer for pixel-wise classification\n",
        "outputs_cnn = layers.Conv2D(3, kernel_size=(3,3), activation=\"softmax\", padding=\"same\")(y)\n",
        "\n",
        "model_cnn = models.Model(inputs_cnn, outputs_cnn)\n",
        "model_cnn.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_cnn.fit(X_cnn, y_cnn, epochs=20, batch_size=1)\n"
      ]
    }
  ]
}