{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/6ZjGAmb89ZowyLOhbe++",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelmccormickudg/Gravitational_housing_model/blob/main/redneural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook completo\n",
        "Predicci贸n de atracci贸n gravitacional entre propiedades y zonas de transformaci贸n territorial con redes neuronales + DENUE\n",
        "0. Instalaci贸n de librer铆as y setup"
      ],
      "metadata": {
        "id": "Akp-A1w3afkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas shapely simplekml\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import tensorflow as tf\n",
        "from itertools import combinations\n",
        "from math import radians, sin, cos, asin, sqrt\n",
        "import simplekml\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "PPzm5Ji-ajMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Carga de archivos base\n",
        "\n",
        "Rutas locales (como las tienes ahora):"
      ],
      "metadata": {
        "id": "vUQMWV8aa9ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Archivos principales del modelo\n",
        "PATH_PROPS   = \"/content/resultados_gravedad_propiedades_v2.xlsx\"\n",
        "PATH_GRAV    = \"/content/gravedad.csv\"\n",
        "PATH_INFL    = \"/content/influence_summary_cat3to5.csv\"\n",
        "PATH_DENUE   = \"/content/denue.xlsx\"\n",
        "\n",
        "# Cargar tablas\n",
        "props = pd.read_excel(PATH_PROPS)\n",
        "grav  = pd.read_csv(PATH_GRAV)\n",
        "infl  = pd.read_csv(PATH_INFL)\n",
        "denue = pd.read_excel(PATH_DENUE)\n",
        "\n",
        "print(\"props:\", props.shape)\n",
        "print(\"grav :\", grav.shape)\n",
        "print(\"infl :\", infl.shape)\n",
        "print(\"denue:\", denue.shape)\n"
      ],
      "metadata": {
        "id": "d42tCzdYbATh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Estandarizaci贸n de columnas y fusiones\n",
        "2.1. Propiedades, gravedad y radio de influencia"
      ],
      "metadata": {
        "id": "lnERNJytd8f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar nombres en props\n",
        "props = props.rename(columns={\n",
        "    \"coordinate/latitude\":  \"lat\",\n",
        "    \"coordinate/longitude\": \"lon\",\n",
        "    \"Masa\": \"mass\",\n",
        "    \"FuerzaTotal\": \"F_total\"\n",
        "})\n",
        "\n",
        "# Normalizar nombres en gravedad\n",
        "grav = grav.rename(columns={\n",
        "    \"coordinate/latitude\":  \"lat\",\n",
        "    \"coordinate/longitude\": \"lon\",\n",
        "    \"F_i\": \"F_node\"   # nombre est谩ndar para F_i de nodo\n",
        "})\n",
        "\n",
        "# Normalizar nombres en influencia\n",
        "infl = infl.rename(columns={\n",
        "    \"gravity_value\": \"F_inf\"\n",
        "})\n",
        "\n",
        "# Redondeo de coordenadas para merge aproximado\n",
        "def round_coords(df, ndigits=5):\n",
        "    df[\"lat_r\"] = df[\"lat\"].round(ndigits)\n",
        "    df[\"lon_r\"] = df[\"lon\"].round(ndigits)\n",
        "    return df\n",
        "\n",
        "props = round_coords(props)\n",
        "grav  = round_coords(grav)\n",
        "infl  = round_coords(infl)\n",
        "\n",
        "# Merge con gravedad\n",
        "props = props.merge(\n",
        "    grav[[\"lat_r\",\"lon_r\",\"S_i\",\"entropy_weight\",\"F_node\"]],\n",
        "    on=[\"lat_r\",\"lon_r\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Merge con resumen de influencia (radio R_influence_km)\n",
        "props = props.merge(\n",
        "    infl[[\"lat_r\",\"lon_r\",\"R_influence_km\"]],\n",
        "    on=[\"lat_r\",\"lon_r\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Rellenar NaN con valores razonables\n",
        "props[\"R_influence_km\"] = props[\"R_influence_km\"].fillna(props[\"R_influence_km\"].median())\n",
        "props[\"S_i\"]            = props[\"S_i\"].fillna(props[\"S_i\"].median())\n",
        "props[\"F_node\"]         = props[\"F_node\"].fillna(props[\"F_node\"].median())\n",
        "\n",
        "print(\"props tras merges:\", props.shape)\n"
      ],
      "metadata": {
        "id": "83XeV1Fdd_IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2. Preparaci贸n de DENUE\n",
        "\n",
        "Columnas reales de tu DENUE:"
      ],
      "metadata": {
        "id": "RiqA425OeRVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(denue.columns)\n"
      ],
      "metadata": {
        "id": "gDG5mZgseUP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tienen latitud, longitud, nombre_act. Las normalizamos:"
      ],
      "metadata": {
        "id": "R-O9GABAeVNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "denue = denue.rename(columns={\n",
        "    \"latitud\": \"lat\",\n",
        "    \"longitud\": \"lon\",\n",
        "    \"nombre_act\": \"actividad\"\n",
        "})\n",
        "\n",
        "print(\"DENUE columnas normalizadas:\", denue[[\"lat\",\"lon\",\"actividad\"]].head())\n"
      ],
      "metadata": {
        "id": "qh4BvB6deXpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. GeoDataFrames y proyecci贸n\n",
        "\n",
        "Usaremos un CRS m茅trico local para Chapala. Ajusta el EPSG si necesitas otro, pero este patr贸n es v谩lido."
      ],
      "metadata": {
        "id": "wui5BSQiecsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Propiedades\n",
        "gdf_props = gpd.GeoDataFrame(\n",
        "    props,\n",
        "    geometry=gpd.points_from_xy(props[\"lon\"], props[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(\"EPSG:6372\")   # CRS m茅trico local (ajustable)\n",
        "\n",
        "# DENUE\n",
        "gdf_denue = gpd.GeoDataFrame(\n",
        "    denue,\n",
        "    geometry=gpd.points_from_xy(denue[\"lon\"], denue[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(gdf_props.crs)\n",
        "\n",
        "print(\"gdf_props:\", gdf_props.shape)\n",
        "print(\"gdf_denue:\", gdf_denue.shape)\n"
      ],
      "metadata": {
        "id": "ndiNL4uOedQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Variables territoriales DENUE por propiedad\n",
        "\n",
        "Calculamos para cada propiedad:\n",
        "\n",
        "denue_total_500m: n煤mero de establecimientos a 500 m\n",
        "\n",
        "denue_turismo_500m: establecimientos tur铆sticos (hotel, alojamiento, restaurantes, bares)\n",
        "\n",
        "denue_diversidad_500m: n煤mero de tipos de actividad distintos"
      ],
      "metadata": {
        "id": "P30LznZnefVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_radius = 500  # metros\n",
        "\n",
        "def es_turismo(act):\n",
        "    if isinstance(act, str):\n",
        "        act_low = act.lower()\n",
        "        if \"hotel\" in act_low or \"alojamiento\" in act_low or \"hospedaje\" in act_low:\n",
        "            return 1\n",
        "        if \"restaurante\" in act_low or \"restaurant\" in act_low or \"bar\" in act_low:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "gdf_denue[\"turistico\"] = gdf_denue[\"actividad\"].apply(es_turismo)\n",
        "\n",
        "denue_total = []\n",
        "denue_tur   = []\n",
        "denue_div   = []\n",
        "\n",
        "for geom in gdf_props.geometry:\n",
        "    buf = geom.buffer(buffer_radius)\n",
        "    df_loc = gdf_denue[gdf_denue.geometry.within(buf)]\n",
        "\n",
        "    denue_total.append(len(df_loc))\n",
        "    denue_tur.append(df_loc[\"turistico\"].sum())\n",
        "    denue_div.append(df_loc[\"actividad\"].nunique())\n",
        "\n",
        "props[\"denue_total_500m\"]      = denue_total\n",
        "props[\"denue_turismo_500m\"]    = denue_tur\n",
        "props[\"denue_diversidad_500m\"] = denue_div\n",
        "\n",
        "print(\"Variables DENUE a帽adidas a props.\")\n"
      ],
      "metadata": {
        "id": "pH-_DyXFeibk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Funci贸n Haversine"
      ],
      "metadata": {
        "id": "5ZwCzEzQerYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def haversine(lat1, lon1, lat2, lon2, R=6371):\n",
        "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2\n",
        "    c = 2*asin(sqrt(a))\n",
        "    return R*c  # km\n"
      ],
      "metadata": {
        "id": "6S6nUrdYesCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Dataset de pares (i, j) y etiqueta Fij\n",
        "\n",
        "Definimos:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "=\n",
        "\n",
        "\n",
        "+\n",
        "\n",
        "\n",
        "2\n",
        "\n",
        "1\n",
        "1\n",
        "+\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "F\n",
        "ij\n",
        "label\n",
        "\t\n",
        "\n",
        "=\n",
        "2\n",
        "F\n",
        "i\n",
        "\t\n",
        "\n",
        "+F\n",
        "j\n",
        "\t\n",
        "\n",
        "\t\n",
        "\n",
        "\n",
        "1+dist\n",
        "ij\n",
        "尾\n",
        "\t\n",
        "\n",
        "1\n",
        "\t\n",
        "\n",
        "\n",
        "y una etiqueta binaria de atracci贸n seg煤n R_influence_km de la propiedad i."
      ],
      "metadata": {
        "id": "b-VaANSDev2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = []\n",
        "beta = 2.0\n",
        "max_radius_km = 3.0  # distancia m谩xima para considerar pares\n",
        "\n",
        "indices = props.index.to_list()\n",
        "\n",
        "for i, j in combinations(indices, 2):\n",
        "    pi = props.loc[i]\n",
        "    pj = props.loc[j]\n",
        "\n",
        "    dist_ij = haversine(pi[\"lat\"], pi[\"lon\"], pj[\"lat\"], pj[\"lon\"])\n",
        "    if dist_ij > max_radius_km:\n",
        "        continue\n",
        "\n",
        "    Fi = pi[\"F_node\"] if not np.isnan(pi[\"F_node\"]) else pi[\"F_total\"]\n",
        "    Fj = pj[\"F_node\"] if not np.isnan(pj[\"F_node\"]) else pj[\"F_total\"]\n",
        "\n",
        "    Fij_label = ((Fi + Fj) / 2.0) * (1.0 / (1.0 + dist_ij**beta))\n",
        "\n",
        "    attract_ij = 1 if dist_ij <= pi[\"R_influence_km\"] else 0\n",
        "\n",
        "    row = {\n",
        "        \"i\": i,\n",
        "        \"j\": j,\n",
        "        \"dist_ij\": dist_ij,\n",
        "        \"mass_i\": pi[\"mass\"],\n",
        "        \"mass_j\": pj[\"mass\"],\n",
        "        \"F_i\": Fi,\n",
        "        \"F_j\": Fj,\n",
        "        \"S_i\": pi[\"S_i\"],\n",
        "        \"S_j\": pj[\"S_i\"],\n",
        "\n",
        "        # variables DENUE por propiedad\n",
        "        \"denue_total_i\":      pi[\"denue_total_500m\"],\n",
        "        \"denue_total_j\":      pj[\"denue_total_500m\"],\n",
        "        \"denue_turismo_i\":    pi[\"denue_turismo_500m\"],\n",
        "        \"denue_turismo_j\":    pj[\"denue_turismo_500m\"],\n",
        "        \"denue_div_i\":        pi[\"denue_diversidad_500m\"],\n",
        "        \"denue_div_j\":        pj[\"denue_diversidad_500m\"],\n",
        "\n",
        "        \"Fij_label\": Fij_label,\n",
        "        \"attract_label\": attract_ij\n",
        "    }\n",
        "    pairs.append(row)\n",
        "\n",
        "pairs_df = pd.DataFrame(pairs)\n",
        "pairs_df = pairs_df.fillna(pairs_df.median(numeric_only=True))\n",
        "\n",
        "print(\"Total de pares generados:\", len(pairs_df))\n"
      ],
      "metadata": {
        "id": "HXqG8a5neyhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. MODELO 1: Red neuronal Fij + Atracci贸n entre propiedades\n",
        "7.1 Preparar features y escalado"
      ],
      "metadata": {
        "id": "Gy1EDqlzfCjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [\n",
        "    \"dist_ij\",\n",
        "    \"mass_i\",\"mass_j\",\n",
        "    \"F_i\",\"F_j\",\n",
        "    \"S_i\",\"S_j\",\n",
        "    \"denue_total_i\",\"denue_total_j\",\n",
        "    \"denue_turismo_i\",\"denue_turismo_j\",\n",
        "    \"denue_div_i\",\"denue_div_j\"\n",
        "]\n",
        "\n",
        "X = pairs_df[feature_cols].values\n",
        "y_reg = pairs_df[\"Fij_label\"].values\n",
        "y_cls = pairs_df[\"attract_label\"].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "Xtr, Xte, yr_tr, yr_te, yc_tr, yc_te = train_test_split(\n",
        "    X_scaled, y_reg, y_cls, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "Xtr.shape, Xte.shape\n"
      ],
      "metadata": {
        "id": "iUUTdmtJfFZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.2 Definir y entrenar modelo multitarea"
      ],
      "metadata": {
        "id": "sg54L9MYfHY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(Xtr.shape[1],))\n",
        "\n",
        "x = tf.keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
        "x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(16, activation=\"relu\")(x)\n",
        "\n",
        "out_reg = tf.keras.layers.Dense(1, name=\"Fij\")(x)\n",
        "out_cls = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"Attr\")(x)\n",
        "\n",
        "model1 = tf.keras.Model(inputs=inputs, outputs=[out_reg, out_cls])\n",
        "\n",
        "model1.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss={\"Fij\": \"mse\", \"Attr\": \"binary_crossentropy\"},\n",
        "    metrics={\"Fij\": \"mae\", \"Attr\": \"accuracy\"}\n",
        ")\n",
        "\n",
        "history1 = model1.fit(\n",
        "    Xtr,\n",
        "    {\"Fij\": yr_tr, \"Attr\": yc_tr},\n",
        "    validation_data=(Xte, {\"Fij\": yr_te, \"Attr\": yc_te}),\n",
        "    epochs=40,\n",
        "    batch_size=32,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        ")\n"
      ],
      "metadata": {
        "id": "vQt5Bn-tfJr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. KML de pares de propiedades atra铆das"
      ],
      "metadata": {
        "id": "pliRRDCFfLig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_fij, pred_attr = model1.predict(X_scaled)\n",
        "pairs_df[\"Fij_pred\"] = pred_fij.flatten()\n",
        "pairs_df[\"attr_prob\"] = pred_attr.flatten()\n",
        "\n",
        "thr_prob = 0.6\n",
        "high_pairs = pairs_df[pairs_df[\"attr_prob\"] >= thr_prob]\n",
        "\n",
        "kml1 = simplekml.Kml()\n",
        "\n",
        "for _, row in high_pairs.iterrows():\n",
        "    pi = props.loc[row[\"i\"]]\n",
        "    pj = props.loc[row[\"j\"]]\n",
        "\n",
        "    ls = kml1.newlinestring(\n",
        "        name=f\"p={row['attr_prob']:.2f}\",\n",
        "        coords=[(pi[\"lon\"], pi[\"lat\"]), (pj[\"lon\"], pj[\"lat\"])]\n",
        "    )\n",
        "    ls.style.linestyle.width = 2\n",
        "\n",
        "kml1.save(\"atraccion_propiedades_fij_denue.kml\")\n",
        "print(\"KML generado: atraccion_propiedades_fij_denue.kml\")\n"
      ],
      "metadata": {
        "id": "E542O-hzfNm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. MODELO 2: Zonas de transformaci贸n territorial (vectorial + DENUE)\n",
        "9.1 Construcci贸n de grilla espacial"
      ],
      "metadata": {
        "id": "QOO1G2TwfPbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minx, miny, maxx, maxy = gdf_props.to_crs(gdf_props.crs).total_bounds\n",
        "cell_size = 150  # metros\n",
        "\n",
        "xs = np.arange(minx, maxx, cell_size)\n",
        "ys = np.arange(miny, maxy, cell_size)\n",
        "\n",
        "polygons = []\n",
        "for x in xs:\n",
        "    for y in ys:\n",
        "        polygons.append(gpd.GeoSeries.box(x, y, x+cell_size, y+cell_size)[0])\n",
        "\n",
        "gdf_grid = gpd.GeoDataFrame(geometry=polygons, crs=gdf_props.crs)\n",
        "\n",
        "print(\"Celdas en grilla:\", gdf_grid.shape)\n"
      ],
      "metadata": {
        "id": "mM5SsSXUfRfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.2 Agregar propiedades a la grilla"
      ],
      "metadata": {
        "id": "f60dUXvVfc-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "join_props = gpd.sjoin(gdf_props, gdf_grid, how=\"left\", predicate=\"within\")\n",
        "\n",
        "agg_props = join_props.groupby(\"index_right\").agg({\n",
        "    \"mass\": \"sum\",\n",
        "    \"F_total\": \"sum\",\n",
        "    \"S_i\": \"mean\",\n",
        "    \"F_node\": \"mean\"\n",
        "}).rename(columns={\n",
        "    \"mass\": \"mass_sum\",\n",
        "    \"F_total\": \"F_sum\",\n",
        "    \"S_i\": \"S_mean\",\n",
        "    \"F_node\": \"Fnode_mean\"\n",
        "})\n",
        "\n",
        "gdf_grid = gdf_grid.join(agg_props, how=\"left\")\n",
        "gdf_grid[[\"mass_sum\",\"F_sum\",\"S_mean\",\"Fnode_mean\"]] = gdf_grid[[\"mass_sum\",\"F_sum\",\"S_mean\",\"Fnode_mean\"]].fillna(0)\n"
      ],
      "metadata": {
        "id": "S9M1_yQRfdaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.3 Agregar DENUE a la grilla"
      ],
      "metadata": {
        "id": "oiHMt91kffAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "join_denue = gpd.sjoin(gdf_denue, gdf_grid, how=\"left\", predicate=\"within\")\n",
        "\n",
        "agg_denue = join_denue.groupby(\"index_right\").agg({\n",
        "    \"actividad\": \"nunique\",\n",
        "    \"turistico\": \"sum\"\n",
        "}).rename(columns={\n",
        "    \"actividad\": \"denue_div_grid\",\n",
        "    \"turistico\": \"denue_turismo_grid\"\n",
        "})\n",
        "\n",
        "gdf_grid = gdf_grid.join(agg_denue, how=\"left\")\n",
        "gdf_grid[[\"denue_div_grid\",\"denue_turismo_grid\"]] = gdf_grid[[\"denue_div_grid\",\"denue_turismo_grid\"]].fillna(0)\n",
        "\n",
        "print(\"gdf_grid con props + DENUE:\", gdf_grid.shape)\n"
      ],
      "metadata": {
        "id": "9BmTuac4fhVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.4 ITT y clases territoriales"
      ],
      "metadata": {
        "id": "RiUY2RrCfjGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1, a2, a3, a4 = 1.0, 0.5, 0.3, 0.4\n",
        "\n",
        "gdf_grid[\"ITT\"] = (\n",
        "    a1*gdf_grid[\"F_sum\"] +\n",
        "    a2*gdf_grid[\"mass_sum\"] -\n",
        "    a3*gdf_grid[\"S_mean\"] +\n",
        "    a4*gdf_grid[\"denue_turismo_grid\"]\n",
        ")\n",
        "\n",
        "q1, q2 = gdf_grid[\"ITT\"].quantile([0.33, 0.66])\n",
        "\n",
        "def classify_ITT(x):\n",
        "    if x <= q1:\n",
        "        return 0  # estable\n",
        "    elif x <= q2:\n",
        "        return 1  # transici贸n\n",
        "    else:\n",
        "        return 2  # alta presi贸n\n",
        "\n",
        "gdf_grid[\"ITT_class\"] = gdf_grid[\"ITT\"].apply(classify_ITT)\n",
        "\n",
        "gdf_grid[[\"ITT\",\"ITT_class\"]].head()\n"
      ],
      "metadata": {
        "id": "GI3heIkFflpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.5 MLP vectorial para ITT + clase"
      ],
      "metadata": {
        "id": "F6HyR9_tfn65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_grid = [\n",
        "    \"mass_sum\",\"F_sum\",\"S_mean\",\"Fnode_mean\",\n",
        "    \"denue_div_grid\",\"denue_turismo_grid\"\n",
        "]\n",
        "\n",
        "Xg = gdf_grid[features_grid].values\n",
        "yI = gdf_grid[\"ITT\"].values\n",
        "yC = gdf_grid[\"ITT_class\"].values\n",
        "\n",
        "scaler_g = StandardScaler()\n",
        "Xg_scaled = scaler_g.fit_transform(Xg)\n",
        "\n",
        "Xg_tr, Xg_te, yI_tr, yI_te, yC_tr, yC_te = train_test_split(\n",
        "    Xg_scaled, yI, yC, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "inp_g = tf.keras.Input(shape=(Xg_tr.shape[1],))\n",
        "z = tf.keras.layers.Dense(32, activation=\"relu\")(inp_g)\n",
        "z = tf.keras.layers.Dense(16, activation=\"relu\")(z)\n",
        "z = tf.keras.layers.Dropout(0.2)(z)\n",
        "\n",
        "ITT_out   = tf.keras.layers.Dense(1, name=\"ITT_out\")(z)\n",
        "Class_out = tf.keras.layers.Dense(3, activation=\"softmax\", name=\"Class_out\")(z)\n",
        "\n",
        "model2 = tf.keras.Model(inp_g, [ITT_out, Class_out])\n",
        "\n",
        "model2.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss={\"ITT_out\": \"mse\", \"Class_out\": \"sparse_categorical_crossentropy\"},\n",
        "    metrics={\"ITT_out\": \"mae\", \"Class_out\": \"accuracy\"}\n",
        ")\n",
        "\n",
        "history2 = model2.fit(\n",
        "    Xg_tr,\n",
        "    {\"ITT_out\": yI_tr, \"Class_out\": yC_tr},\n",
        "    validation_data=(Xg_te, {\"ITT_out\": yI_te, \"Class_out\": yC_te}),\n",
        "    epochs=40,\n",
        "    batch_size=32,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        ")\n"
      ],
      "metadata": {
        "id": "g7qhMRZefpyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.6 Predicciones y KML de zonas de transformaci贸n"
      ],
      "metadata": {
        "id": "Mpdit2E4fr0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xg_all = scaler_g.transform(gdf_grid[features_grid].values)\n",
        "ITT_pred_all, Class_pred_all = model2.predict(Xg_all)\n",
        "\n",
        "gdf_grid[\"ITT_pred\"]   = ITT_pred_all.flatten()\n",
        "gdf_grid[\"Class_pred\"] = Class_pred_all.argmax(axis=1)\n",
        "\n",
        "kml2 = simplekml.Kml()\n",
        "\n",
        "for _, row in gdf_grid[gdf_grid[\"Class_pred\"]==2].iterrows():\n",
        "    poly = row.geometry\n",
        "    pol = kml2.newpolygon()\n",
        "    pol.outerboundaryis = list(poly.exterior.coords)\n",
        "    pol.style.polystyle.color = simplekml.Color.changealphaint(120, simplekml.Color.red)\n",
        "\n",
        "kml2.save(\"zonas_transformacion_denue.kml\")\n",
        "print(\"KML generado: zonas_transformacion_denue.kml\")\n"
      ],
      "metadata": {
        "id": "or_6PYOvfuJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. CNN espacial (opcional) para validaci贸n cruzada\n",
        "\n",
        "Si quieres la parte raster / CNN, puedes a帽adir esta secci贸n. Si por ahora quieres mantenerlo simple, puedes omitirla."
      ],
      "metadata": {
        "id": "d3wPmhv3fwgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignar 铆ndices de fila/columna a cada celda de la grilla\n",
        "gdf_grid[\"centroid\"] = gdf_grid.geometry.centroid\n",
        "minx_c, miny_c, maxx_c, maxy_c = gdf_grid.total_bounds\n",
        "\n",
        "gdf_grid[\"row\"] = ((gdf_grid[\"centroid\"].y - miny_c) // cell_size).astype(int)\n",
        "gdf_grid[\"col\"] = ((gdf_grid[\"centroid\"].x - minx_c) // cell_size).astype(int)\n",
        "\n",
        "max_row = gdf_grid[\"row\"].max() + 1\n",
        "max_col = gdf_grid[\"col\"].max() + 1\n",
        "\n",
        "channels = features_grid  # mismas variables de entrada\n",
        "grid_tensor = np.zeros((max_row, max_col, len(channels)), dtype=float)\n",
        "label_tensor = np.zeros((max_row, max_col), dtype=int)\n",
        "\n",
        "for _, r in gdf_grid.iterrows():\n",
        "    i = r[\"row\"]\n",
        "    j = r[\"col\"]\n",
        "    for c_idx, c_name in enumerate(channels):\n",
        "        grid_tensor[i, j, c_idx] = r[c_name]\n",
        "    label_tensor[i, j] = r[\"ITT_class\"]\n",
        "\n",
        "# Normalizaci贸n por canal\n",
        "for c_idx in range(len(channels)):\n",
        "    ch = grid_tensor[:, :, c_idx]\n",
        "    mu = ch.mean()\n",
        "    sigma = ch.std() if ch.std() > 0 else 1.0\n",
        "    grid_tensor[:, :, c_idx] = (ch - mu) / sigma\n",
        "\n",
        "# A帽adir dimensi贸n batch\n",
        "X_cnn = np.expand_dims(grid_tensor, axis=0)\n",
        "y_cnn = np.expand_dims(label_tensor, axis=0)\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "input_shape = X_cnn.shape[1:]\n",
        "\n",
        "inputs_cnn = layers.Input(shape=input_shape)\n",
        "y = layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(inputs_cnn)\n",
        "y = layers.MaxPooling2D((2,2))(y)\n",
        "y = layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(y)\n",
        "y = layers.MaxPooling2D((2,2))(y)\n",
        "y = layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(y)\n",
        "y = layers.Flatten()(y)\n",
        "y = layers.Dense(64, activation=\"relu\")(y)\n",
        "y = layers.Dropout(0.3)(y)\n",
        "outputs_cnn = layers.Dense(3, activation=\"softmax\")(y)\n",
        "\n",
        "model_cnn = models.Model(inputs_cnn, outputs_cnn)\n",
        "model_cnn.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_cnn.fit(X_cnn, y_cnn, epochs=20, batch_size=1)\n"
      ],
      "metadata": {
        "id": "8r4BK7yTfy8c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}